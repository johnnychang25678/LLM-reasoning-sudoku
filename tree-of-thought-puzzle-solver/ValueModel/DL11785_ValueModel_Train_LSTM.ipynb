{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "exWD1mCoimNl"
      },
      "outputs": [],
      "source": [
        "file_names = [\"/content/mcts_puzzle_{}_results.csv\".format(i) for i in range(1, 24) ]\n",
        "\n",
        "dataframes = []\n",
        "\n",
        "for file in file_names:\n",
        "    df = pd.read_csv(file)\n",
        "    dataframes.append(df)\n",
        "\n",
        "combined_df = pd.concat(dataframes, ignore_index=True)\n",
        "\n",
        "shuffled_df = combined_df.sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "print(shuffled_df.head())\n",
        "\n",
        "shuffled_df.to_csv(\"/content/shuffled_results.csv\", index=False)\n",
        "df_original = pd.read_csv(\"/content/shuffled_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def generate_invalid_sudoku():\n",
        "    grid = [[str(random.randint(1, 3)) for _ in range(3)] for _ in range(3)]\n",
        "    return str(grid)\n",
        "\n",
        "invalid_states = [{\"state\": generate_invalid_sudoku(), \"q_value\": -1.0} for _ in range(500)]\n",
        "\n",
        "def generate_close_sudoku():\n",
        "    grid = [[str((i + j) % 3 + 1) for j in range(3)] for i in range(3)]\n",
        "    if random.random() > 0.5:\n",
        "        grid[random.randint(0, 2)][random.randint(0, 2)] = '*'\n",
        "    return str(grid)\n",
        "\n",
        "close_states = [{\"state\": generate_close_sudoku(), \"q_value\": random.uniform(0.5, 0.9)} for _ in range(500)]\n",
        "\n",
        "\n",
        "def generate_neutral_sudoku():\n",
        "    \"\"\"\n",
        "    Generates a 3x3 grid that:\n",
        "    - Fills some cells without violating Sudoku rules.\n",
        "    - Ensures no duplicates in rows or columns.\n",
        "    - Leaves enough empty cells to be considered \"neutral.\"\n",
        "    \"\"\"\n",
        "\n",
        "    grid = [['*' for _ in range(3)] for _ in range(3)]\n",
        "\n",
        "\n",
        "    for i in range(3):\n",
        "        used = set()\n",
        "        for j in range(3):\n",
        "            if random.random() > 0.7:\n",
        "                num = str(random.randint(1, 3))\n",
        "                while num in used:\n",
        "                    num = str(random.randint(1, 3))\n",
        "                grid[i][j] = num\n",
        "                used.add(num)\n",
        "\n",
        "\n",
        "    for col_idx in range(3):\n",
        "        col_values = [grid[row_idx][col_idx] for row_idx in range(3) if grid[row_idx][col_idx] != '*']\n",
        "        if len(col_values) != len(set(col_values)):\n",
        "\n",
        "            for row_idx in range(3):\n",
        "                grid[row_idx][col_idx] = '*'\n",
        "\n",
        "    return grid\n",
        "\n",
        "\n",
        "neutral_states = []\n",
        "for _ in range(500):\n",
        "    state = generate_neutral_sudoku()\n",
        "    q_value = random.uniform(0.0, 0.2)\n",
        "    neutral_states.append({\"state\": str(state), \"q_value\": round(q_value, 3)})\n",
        "\n",
        "\n",
        "for example in neutral_states[:5]:\n",
        "    print(f\"State: {example['state']}\")\n",
        "    print(f\"Q-Value: {example['q_value']}\\n\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FPBTi2TQiscB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "\n",
        "class TextRegressionDataset(Dataset):\n",
        "    def __init__(self, texts, targets, tokenizer, max_len):\n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        target = self.targets[idx]\n",
        "\n",
        "        tokenized = self.tokenizer(\n",
        "            text, padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors=\"pt\"\n",
        "        )\n",
        "        return {\n",
        "            \"input_ids\": tokenized[\"input_ids\"].squeeze(0),\n",
        "            \"attention_mask\": tokenized[\"attention_mask\"].squeeze(0),\n",
        "            \"target\": torch.tensor(target, dtype=torch.float)\n",
        "        }\n",
        "\n",
        "\n",
        "class LSTMRegressor(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx):\n",
        "        super(LSTMRegressor, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        embedded = self.embedding(input_ids)\n",
        "        packed_output, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(hidden[-1])\n",
        "        return self.activation(output)\n",
        "\n",
        "\n",
        "texts = list(df_combined['state'])\n",
        "targets = list(df_combined['q_value'])\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "max_len = 50\n",
        "\n",
        "dataset = TextRegressionDataset(texts, targets, tokenizer, max_len)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=2)\n",
        "\n",
        "\n",
        "vocab_size = tokenizer.vocab_size\n",
        "embedding_dim = 128\n",
        "hidden_dim = 64\n",
        "output_dim = 1\n",
        "pad_idx = tokenizer.pad_token_id\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMRegressor(vocab_size, embedding_dim, hidden_dim, output_dim, pad_idx).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "epochs = 7\n",
        "for epoch in range(epochs):\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    epoch_train_loss = 0\n",
        "    for batch in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        input_ids = batch[\"input_ids\"].to(device)\n",
        "        attention_mask = batch[\"attention_mask\"].to(device)\n",
        "        targets = batch[\"target\"].to(device)\n",
        "\n",
        "        predictions = model(input_ids, attention_mask)\n",
        "        loss = criterion(predictions.squeeze(), targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_train_loss += loss.item()\n",
        "\n",
        "    # Validation phase\n",
        "    model.eval()\n",
        "    epoch_val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch in val_loader:\n",
        "            input_ids = batch[\"input_ids\"].to(device)\n",
        "            attention_mask = batch[\"attention_mask\"].to(device)\n",
        "            targets = batch[\"target\"].to(device)\n",
        "\n",
        "            predictions = model(input_ids, attention_mask)\n",
        "            loss = criterion(predictions.squeeze(), targets)\n",
        "            epoch_val_loss += loss.item()\n",
        "\n",
        "    print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {epoch_train_loss / len(train_loader):.4f}, \"\n",
        "          f\"Validation Loss: {epoch_val_loss / len(val_loader):.4f}\")"
      ],
      "metadata": {
        "id": "Qxq7Ihdgis9r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts = [\n",
        "    # Test 1: A typical puzzle with a mix of numbers\n",
        "    \"[['1', '3', '2'], ['2', '1', '3'], ['3', '2', '1']]\",\n",
        "    # Test 2: A uniform puzzle\n",
        "    \"[['1', '1', '1'], ['1', '1', '1'], ['1', '1', '1']]\",\n",
        "    # Test 3: A puzzle with stars ('*') representing unknown values\n",
        "    \"[['*', '3', '2'], ['2', '*', '*'], ['3', '*', '1']]\",\n",
        "    # Test 4: A partially solved puzzle\n",
        "    \"[['1', '3', '2'], ['2', '1', '3'], ['3', '*', '*']]\",\n",
        "    # Test 5: A puzzle with descending numbers\n",
        "    \"[['3', '2', '1'], ['3', '2', '1'], ['3', '2', '1']]\",\n",
        "    # Test 6: A diagonal puzzle\n",
        "    \"[['1', '*', '*'], ['*', '2', '*'], ['*', '*', '3']]\",\n",
        "    # Test 7: Randomized puzzle values\n",
        "    \"[['3', '1', '2'], ['2', '3', '1'], ['1', '2', '3']]\",\n",
        "    # Test 8: An edge case with all zeros\n",
        "    \"[['0', '0', '0'], ['0', '0', '0'], ['0', '0', '0']]\",\n",
        "    # Test 9: A puzzle with mixed known and unknown values\n",
        "    \"[['1', '*', '2'], ['*', '1', '*'], ['2', '*', '3']]\",\n",
        "    # Test 10: An inverse diagonal pattern\n",
        "    \"[['*', '*', '1'], ['*', '2', '*'], ['3', '*', '*']]\"\n",
        "]\n",
        "\n",
        "input_data = tokenizer(\n",
        "    input_texts, padding=\"max_length\", truncation=True, max_length=max_len, return_tensors=\"pt\"\n",
        ")\n",
        "input_ids = input_data[\"input_ids\"].to(device)\n",
        "attention_mask = input_data[\"attention_mask\"].to(device)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    predicted_scores = model(input_ids, attention_mask)\n",
        "\n",
        "for text, score in zip(input_texts, predicted_scores.squeeze().tolist()):\n",
        "    print(f\"Puzzle: {text}\")\n",
        "    print(f\"Predicted Score: {score:.4f}\")"
      ],
      "metadata": {
        "id": "1wioCwVsiwLy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_save_path = \"lstm_regressor.pth\"\n",
        "torch.save(model.state_dict(), model_save_path)\n",
        "print(f\"Model saved to {model_save_path}\")"
      ],
      "metadata": {
        "id": "lvv-CHqBkGc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}